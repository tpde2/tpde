; NOTE: Assertions have been autogenerated by test/update_tpde_llc_test_checks.py UTC_ARGS: --version 5
; SPDX-FileCopyrightText: 2025 Contributors to TPDE <https://tpde.org>
; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

; RUN: tpde-llc --target=x86_64 %s | %objdump | FileCheck %s -check-prefixes=X64
; RUN: tpde-llc --target=aarch64 %s | %objdump | FileCheck %s -check-prefixes=ARM64

define void @ashr_v1i8(ptr %p, ptr %q) {
; X64-LABEL: <ashr_v1i8>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movzx eax, byte ptr [rdi]
; X64-NEXT:    movzx ecx, byte ptr [rsi]
; X64-NEXT:    movsx eax, al
; X64-NEXT:    mov byte ptr [rbp - 0x29], cl
; X64-NEXT:    movzx edx, byte ptr [rbp - 0x29]
; X64-NEXT:    mov ecx, edx
; X64-NEXT:    sar eax, cl
; X64-NEXT:    mov byte ptr [rdi], al
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v1i8>:
; ARM64:         ldrb w2, [x0]
; ARM64-NEXT:    ldrb w3, [x1]
; ARM64-NEXT:    sxtb w2, w2
; ARM64-NEXT:    asr w2, w2, w3
; ARM64-NEXT:    strb w2, [x0]
; ARM64-NEXT:    ret
  %a = load <1 x i8>, ptr %p
  %b = load <1 x i8>, ptr %q
  %r = ashr <1 x i8> %a, %b
  store <1 x i8> %r, ptr %p
  ret void
}

define void @ashr_v1i8_3(ptr %p) {
; X64-LABEL: <ashr_v1i8_3>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movzx eax, byte ptr [rdi]
; X64-NEXT:    movsx eax, al
; X64-NEXT:    sar eax, 0x3
; X64-NEXT:    mov byte ptr [rdi], al
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v1i8_3>:
; ARM64:         ldrb w1, [x0]
; ARM64-NEXT:    sxtb w1, w1
; ARM64-NEXT:    asr w1, w1, #3
; ARM64-NEXT:    strb w1, [x0]
; ARM64-NEXT:    ret
  %a = load <1 x i8>, ptr %p
  %r = ashr <1 x i8> %a, <i8 3>
  store <1 x i8> %r, ptr %p
  ret void
}

define void @ashr_v5i8(ptr %p, ptr %q) {
; X64-LABEL: <ashr_v5i8>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    push rbx
; X64-NEXT:    push r12
; X64-NEXT:    push r13
; X64-NEXT:    movzx eax, byte ptr [rdi]
; X64-NEXT:    movzx ecx, byte ptr [rdi + 0x1]
; X64-NEXT:    movzx edx, byte ptr [rdi + 0x2]
; X64-NEXT:    movzx ebx, byte ptr [rdi + 0x3]
; X64-NEXT:    movzx r8d, byte ptr [rdi + 0x4]
; X64-NEXT:    movzx r9d, byte ptr [rsi]
; X64-NEXT:    movzx r10d, byte ptr [rsi + 0x1]
; X64-NEXT:    movzx r11d, byte ptr [rsi + 0x2]
; X64-NEXT:    movzx r12d, byte ptr [rsi + 0x3]
; X64-NEXT:    movzx r13d, byte ptr [rsi + 0x4]
; X64-NEXT:    movsx eax, al
; X64-NEXT:    mov byte ptr [rbp - 0x2f], cl
; X64-NEXT:    mov ecx, r9d
; X64-NEXT:    sar eax, cl
; X64-NEXT:    movzx ecx, byte ptr [rbp - 0x2f]
; X64-NEXT:    movsx ecx, cl
; X64-NEXT:    mov rsi, rcx
; X64-NEXT:    mov ecx, r10d
; X64-NEXT:    sar esi, cl
; X64-NEXT:    movsx edx, dl
; X64-NEXT:    mov ecx, r11d
; X64-NEXT:    sar edx, cl
; X64-NEXT:    movsx ebx, bl
; X64-NEXT:    mov ecx, r12d
; X64-NEXT:    sar ebx, cl
; X64-NEXT:    movsx r8d, r8b
; X64-NEXT:    mov ecx, r13d
; X64-NEXT:    sar r8d, cl
; X64-NEXT:    mov byte ptr [rdi], al
; X64-NEXT:    mov byte ptr [rdi + 0x1], sil
; X64-NEXT:    mov byte ptr [rdi + 0x2], dl
; X64-NEXT:    mov byte ptr [rdi + 0x3], bl
; X64-NEXT:    mov byte ptr [rdi + 0x4], r8b
; X64-NEXT:    pop r13
; X64-NEXT:    pop r12
; X64-NEXT:    pop rbx
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v5i8>:
; ARM64:         ldrb w2, [x0]
; ARM64-NEXT:    ldrb w3, [x0, #0x1]
; ARM64-NEXT:    ldrb w4, [x0, #0x2]
; ARM64-NEXT:    ldrb w5, [x0, #0x3]
; ARM64-NEXT:    ldrb w6, [x0, #0x4]
; ARM64-NEXT:    ldrb w7, [x1]
; ARM64-NEXT:    ldrb w8, [x1, #0x1]
; ARM64-NEXT:    ldrb w9, [x1, #0x2]
; ARM64-NEXT:    ldrb w10, [x1, #0x3]
; ARM64-NEXT:    ldrb w11, [x1, #0x4]
; ARM64-NEXT:    sxtb w2, w2
; ARM64-NEXT:    asr w2, w2, w7
; ARM64-NEXT:    sxtb w3, w3
; ARM64-NEXT:    asr w3, w3, w8
; ARM64-NEXT:    sxtb w4, w4
; ARM64-NEXT:    asr w4, w4, w9
; ARM64-NEXT:    sxtb w5, w5
; ARM64-NEXT:    asr w5, w5, w10
; ARM64-NEXT:    sxtb w6, w6
; ARM64-NEXT:    asr w6, w6, w11
; ARM64-NEXT:    strb w2, [x0]
; ARM64-NEXT:    strb w3, [x0, #0x1]
; ARM64-NEXT:    strb w4, [x0, #0x2]
; ARM64-NEXT:    strb w5, [x0, #0x3]
; ARM64-NEXT:    strb w6, [x0, #0x4]
; ARM64-NEXT:    ret
  %a = load <5 x i8>, ptr %p
  %b = load <5 x i8>, ptr %q
  %r = ashr <5 x i8> %a, %b
  store <5 x i8> %r, ptr %p
  ret void
}

define void @ashr_v5i8_3(ptr %p) {
; X64-LABEL: <ashr_v5i8_3>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    push rbx
; X64-NEXT:    movzx eax, byte ptr [rdi]
; X64-NEXT:    movzx ecx, byte ptr [rdi + 0x1]
; X64-NEXT:    movzx edx, byte ptr [rdi + 0x2]
; X64-NEXT:    movzx ebx, byte ptr [rdi + 0x3]
; X64-NEXT:    movzx esi, byte ptr [rdi + 0x4]
; X64-NEXT:    movsx eax, al
; X64-NEXT:    sar eax, 0x3
; X64-NEXT:    movsx ecx, cl
; X64-NEXT:    sar ecx, 0x3
; X64-NEXT:    movsx edx, dl
; X64-NEXT:    sar edx, 0x3
; X64-NEXT:    movsx ebx, bl
; X64-NEXT:    sar ebx, 0x3
; X64-NEXT:    movsx esi, sil
; X64-NEXT:    sar esi, 0x3
; X64-NEXT:    mov byte ptr [rdi], al
; X64-NEXT:    mov byte ptr [rdi + 0x1], cl
; X64-NEXT:    mov byte ptr [rdi + 0x2], dl
; X64-NEXT:    mov byte ptr [rdi + 0x3], bl
; X64-NEXT:    mov byte ptr [rdi + 0x4], sil
; X64-NEXT:    pop rbx
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v5i8_3>:
; ARM64:         ldrb w1, [x0]
; ARM64-NEXT:    ldrb w2, [x0, #0x1]
; ARM64-NEXT:    ldrb w3, [x0, #0x2]
; ARM64-NEXT:    ldrb w4, [x0, #0x3]
; ARM64-NEXT:    ldrb w5, [x0, #0x4]
; ARM64-NEXT:    sxtb w1, w1
; ARM64-NEXT:    asr w1, w1, #3
; ARM64-NEXT:    sxtb w2, w2
; ARM64-NEXT:    asr w2, w2, #3
; ARM64-NEXT:    sxtb w3, w3
; ARM64-NEXT:    asr w3, w3, #3
; ARM64-NEXT:    sxtb w4, w4
; ARM64-NEXT:    asr w4, w4, #3
; ARM64-NEXT:    sxtb w5, w5
; ARM64-NEXT:    asr w5, w5, #3
; ARM64-NEXT:    strb w1, [x0]
; ARM64-NEXT:    strb w2, [x0, #0x1]
; ARM64-NEXT:    strb w3, [x0, #0x2]
; ARM64-NEXT:    strb w4, [x0, #0x3]
; ARM64-NEXT:    strb w5, [x0, #0x4]
; ARM64-NEXT:    ret
  %a = load <5 x i8>, ptr %p
  %r = ashr <5 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3>
  store <5 x i8> %r, ptr %p
  ret void
}

define <8 x i8> @ashr_v8i8(<8 x i8> %a, <8 x i8> %b) {
; X64-LABEL: <ashr_v8i8>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    punpcklbw {{.*#+}} xmm0 = xmm0[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    psllw xmm1, 0x5
; X64-NEXT:    punpcklbw {{.*#+}} xmm1 = xmm1[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    pxor xmm2, xmm2
; X64-NEXT:    pxor xmm3, xmm3
; X64-NEXT:    pcmpgtw xmm3, xmm1
; X64-NEXT:    movdqa xmm4, xmm3
; X64-NEXT:    pandn xmm4, xmm0
; X64-NEXT:    psraw xmm0, 0x4
; X64-NEXT:    pand xmm0, xmm3
; X64-NEXT:    por xmm0, xmm4
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    pxor xmm3, xmm3
; X64-NEXT:    pcmpgtw xmm3, xmm1
; X64-NEXT:    movdqa xmm4, xmm3
; X64-NEXT:    pandn xmm4, xmm0
; X64-NEXT:    psraw xmm0, 0x2
; X64-NEXT:    pand xmm0, xmm3
; X64-NEXT:    por xmm0, xmm4
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    pcmpgtw xmm2, xmm1
; X64-NEXT:    movdqa xmm1, xmm2
; X64-NEXT:    pandn xmm1, xmm0
; X64-NEXT:    psraw xmm0, 0x1
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm1
; X64-NEXT:    psrlw xmm0, 0x8
; X64-NEXT:    packuswb xmm0, xmm0
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v8i8>:
; ARM64:         neg v1.8b, v1.8b
; ARM64-NEXT:    sshl v0.8b, v0.8b, v1.8b
; ARM64-NEXT:    ret
  %r = ashr <8 x i8> %a, %b
  ret <8 x i8> %r
}

define <8 x i8> @ashr_v8i8_3(<8 x i8> %a) {
; X64-LABEL: <ashr_v8i8_3>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    punpcklbw {{.*#+}} xmm0 = xmm0[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    movabs rax, 0x303030303030303
; X64-NEXT:    movq xmm1, rax
; X64-NEXT:    psllw xmm1, 0x5
; X64-NEXT:    punpcklbw {{.*#+}} xmm1 = xmm1[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    pxor xmm2, xmm2
; X64-NEXT:    pxor xmm3, xmm3
; X64-NEXT:    pcmpgtw xmm3, xmm1
; X64-NEXT:    movdqa xmm4, xmm3
; X64-NEXT:    pandn xmm4, xmm0
; X64-NEXT:    psraw xmm0, 0x4
; X64-NEXT:    pand xmm0, xmm3
; X64-NEXT:    por xmm0, xmm4
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    pxor xmm3, xmm3
; X64-NEXT:    pcmpgtw xmm3, xmm1
; X64-NEXT:    movdqa xmm4, xmm3
; X64-NEXT:    pandn xmm4, xmm0
; X64-NEXT:    psraw xmm0, 0x2
; X64-NEXT:    pand xmm0, xmm3
; X64-NEXT:    por xmm0, xmm4
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    pcmpgtw xmm2, xmm1
; X64-NEXT:    movdqa xmm1, xmm2
; X64-NEXT:    pandn xmm1, xmm0
; X64-NEXT:    psraw xmm0, 0x1
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm1
; X64-NEXT:    psrlw xmm0, 0x8
; X64-NEXT:    packuswb xmm0, xmm0
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v8i8_3>:
; ARM64:         movi v1.8b, #0x3
; ARM64-NEXT:    neg v1.8b, v1.8b
; ARM64-NEXT:    sshl v0.8b, v0.8b, v1.8b
; ARM64-NEXT:    ret
  %r = ashr <8 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  ret <8 x i8> %r
}

define <16 x i8> @ashr_v16i8(<16 x i8> %a, <16 x i8> %b) {
; X64-LABEL: <ashr_v16i8>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    punpckhbw {{.*#+}} xmm2 = xmm2[8],xmm0[8],xmm2[9],xmm0[9],xmm2[10],xmm0[10],xmm2[11],xmm0[11],xmm2[12],xmm0[12],xmm2[13],xmm0[13],xmm2[14],xmm0[14],xmm2[15],xmm0[15]
; X64-NEXT:    psllw xmm1, 0x5
; X64-NEXT:    punpckhbw {{.*#+}} xmm3 = xmm3[8],xmm1[8],xmm3[9],xmm1[9],xmm3[10],xmm1[10],xmm3[11],xmm1[11],xmm3[12],xmm1[12],xmm3[13],xmm1[13],xmm3[14],xmm1[14],xmm3[15],xmm1[15]
; X64-NEXT:    pxor xmm4, xmm4
; X64-NEXT:    pxor xmm5, xmm5
; X64-NEXT:    pcmpgtw xmm5, xmm3
; X64-NEXT:    movdqa xmm6, xmm5
; X64-NEXT:    pandn xmm6, xmm2
; X64-NEXT:    psraw xmm2, 0x4
; X64-NEXT:    pand xmm2, xmm5
; X64-NEXT:    por xmm2, xmm6
; X64-NEXT:    paddw xmm3, xmm3
; X64-NEXT:    pxor xmm5, xmm5
; X64-NEXT:    pcmpgtw xmm5, xmm3
; X64-NEXT:    movdqa xmm6, xmm5
; X64-NEXT:    pandn xmm6, xmm2
; X64-NEXT:    psraw xmm2, 0x2
; X64-NEXT:    pand xmm2, xmm5
; X64-NEXT:    por xmm2, xmm6
; X64-NEXT:    paddw xmm3, xmm3
; X64-NEXT:    pxor xmm5, xmm5
; X64-NEXT:    pcmpgtw xmm5, xmm3
; X64-NEXT:    movdqa xmm3, xmm5
; X64-NEXT:    pandn xmm3, xmm2
; X64-NEXT:    psraw xmm2, 0x1
; X64-NEXT:    pand xmm2, xmm5
; X64-NEXT:    por xmm2, xmm3
; X64-NEXT:    psrlw xmm2, 0x8
; X64-NEXT:    punpcklbw {{.*#+}} xmm0 = xmm0[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    punpcklbw {{.*#+}} xmm1 = xmm1[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    pxor xmm3, xmm3
; X64-NEXT:    pcmpgtw xmm3, xmm1
; X64-NEXT:    movdqa xmm5, xmm3
; X64-NEXT:    pandn xmm5, xmm0
; X64-NEXT:    psraw xmm0, 0x4
; X64-NEXT:    pand xmm0, xmm3
; X64-NEXT:    por xmm0, xmm5
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    pxor xmm3, xmm3
; X64-NEXT:    pcmpgtw xmm3, xmm1
; X64-NEXT:    movdqa xmm5, xmm3
; X64-NEXT:    pandn xmm5, xmm0
; X64-NEXT:    psraw xmm0, 0x2
; X64-NEXT:    pand xmm0, xmm3
; X64-NEXT:    por xmm0, xmm5
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    pcmpgtw xmm4, xmm1
; X64-NEXT:    movdqa xmm1, xmm4
; X64-NEXT:    pandn xmm1, xmm0
; X64-NEXT:    psraw xmm0, 0x1
; X64-NEXT:    pand xmm0, xmm4
; X64-NEXT:    por xmm0, xmm1
; X64-NEXT:    psrlw xmm0, 0x8
; X64-NEXT:    packuswb xmm0, xmm2
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v16i8>:
; ARM64:         neg v1.16b, v1.16b
; ARM64-NEXT:    sshl v0.16b, v0.16b, v1.16b
; ARM64-NEXT:    ret
  %r = ashr <16 x i8> %a, %b
  ret <16 x i8> %r
}

define <16 x i8> @ashr_v16i8_3(<16 x i8> %a) {
; X64-LABEL: <ashr_v16i8_3>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    punpckhbw {{.*#+}} xmm1 = xmm1[8],xmm0[8],xmm1[9],xmm0[9],xmm1[10],xmm0[10],xmm1[11],xmm0[11],xmm1[12],xmm0[12],xmm1[13],xmm0[13],xmm1[14],xmm0[14],xmm1[15],xmm0[15]
; X64-NEXT:    movaps xmm2, xmmword ptr <ashr_v16i8_3+0x7>
; X64-NEXT:     R_X86_64_PC32 -0x4
; X64-NEXT:    psllw xmm2, 0x5
; X64-NEXT:    punpckhbw {{.*#+}} xmm3 = xmm3[8],xmm2[8],xmm3[9],xmm2[9],xmm3[10],xmm2[10],xmm3[11],xmm2[11],xmm3[12],xmm2[12],xmm3[13],xmm2[13],xmm3[14],xmm2[14],xmm3[15],xmm2[15]
; X64-NEXT:    pxor xmm4, xmm4
; X64-NEXT:    pxor xmm5, xmm5
; X64-NEXT:    pcmpgtw xmm5, xmm3
; X64-NEXT:    movdqa xmm6, xmm5
; X64-NEXT:    pandn xmm6, xmm1
; X64-NEXT:    psraw xmm1, 0x4
; X64-NEXT:    pand xmm1, xmm5
; X64-NEXT:    por xmm1, xmm6
; X64-NEXT:    paddw xmm3, xmm3
; X64-NEXT:    pxor xmm5, xmm5
; X64-NEXT:    pcmpgtw xmm5, xmm3
; X64-NEXT:    movdqa xmm6, xmm5
; X64-NEXT:    pandn xmm6, xmm1
; X64-NEXT:    psraw xmm1, 0x2
; X64-NEXT:    pand xmm1, xmm5
; X64-NEXT:    por xmm1, xmm6
; X64-NEXT:    paddw xmm3, xmm3
; X64-NEXT:    pxor xmm5, xmm5
; X64-NEXT:    pcmpgtw xmm5, xmm3
; X64-NEXT:    movdqa xmm3, xmm5
; X64-NEXT:    pandn xmm3, xmm1
; X64-NEXT:    psraw xmm1, 0x1
; X64-NEXT:    pand xmm1, xmm5
; X64-NEXT:    por xmm1, xmm3
; X64-NEXT:    psrlw xmm1, 0x8
; X64-NEXT:    punpcklbw {{.*#+}} xmm0 = xmm0[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    punpcklbw {{.*#+}} xmm2 = xmm2[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    pxor xmm3, xmm3
; X64-NEXT:    pcmpgtw xmm3, xmm2
; X64-NEXT:    movdqa xmm5, xmm3
; X64-NEXT:    pandn xmm5, xmm0
; X64-NEXT:    psraw xmm0, 0x4
; X64-NEXT:    pand xmm0, xmm3
; X64-NEXT:    por xmm0, xmm5
; X64-NEXT:    paddw xmm2, xmm2
; X64-NEXT:    pxor xmm3, xmm3
; X64-NEXT:    pcmpgtw xmm3, xmm2
; X64-NEXT:    movdqa xmm5, xmm3
; X64-NEXT:    pandn xmm5, xmm0
; X64-NEXT:    psraw xmm0, 0x2
; X64-NEXT:    pand xmm0, xmm3
; X64-NEXT:    por xmm0, xmm5
; X64-NEXT:    paddw xmm2, xmm2
; X64-NEXT:    pcmpgtw xmm4, xmm2
; X64-NEXT:    movdqa xmm2, xmm4
; X64-NEXT:    pandn xmm2, xmm0
; X64-NEXT:    psraw xmm0, 0x1
; X64-NEXT:    pand xmm0, xmm4
; X64-NEXT:    por xmm0, xmm2
; X64-NEXT:    psrlw xmm0, 0x8
; X64-NEXT:    packuswb xmm0, xmm1
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v16i8_3>:
; ARM64:         movi v1.16b, #0x3
; ARM64-NEXT:    neg v1.16b, v1.16b
; ARM64-NEXT:    sshl v0.16b, v0.16b, v1.16b
; ARM64-NEXT:    ret
  %r = ashr <16 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  ret <16 x i8> %r
}

define void @ashr_v32i8(ptr %p, ptr %q) {
; X64-LABEL: <ashr_v32i8>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movups xmm0, xmmword ptr [rdi]
; X64-NEXT:    movups xmm1, xmmword ptr [rdi + 0x10]
; X64-NEXT:    movups xmm2, xmmword ptr [rsi]
; X64-NEXT:    movups xmm3, xmmword ptr [rsi + 0x10]
; X64-NEXT:    punpckhbw {{.*#+}} xmm4 = xmm4[8],xmm0[8],xmm4[9],xmm0[9],xmm4[10],xmm0[10],xmm4[11],xmm0[11],xmm4[12],xmm0[12],xmm4[13],xmm0[13],xmm4[14],xmm0[14],xmm4[15],xmm0[15]
; X64-NEXT:    psllw xmm2, 0x5
; X64-NEXT:    punpckhbw {{.*#+}} xmm5 = xmm5[8],xmm2[8],xmm5[9],xmm2[9],xmm5[10],xmm2[10],xmm5[11],xmm2[11],xmm5[12],xmm2[12],xmm5[13],xmm2[13],xmm5[14],xmm2[14],xmm5[15],xmm2[15]
; X64-NEXT:    pxor xmm6, xmm6
; X64-NEXT:    pxor xmm7, xmm7
; X64-NEXT:    pcmpgtw xmm7, xmm5
; X64-NEXT:    movdqa xmm8, xmm7
; X64-NEXT:    pandn xmm8, xmm4
; X64-NEXT:    psraw xmm4, 0x4
; X64-NEXT:    pand xmm4, xmm7
; X64-NEXT:    por xmm4, xmm8
; X64-NEXT:    paddw xmm5, xmm5
; X64-NEXT:    pxor xmm7, xmm7
; X64-NEXT:    pcmpgtw xmm7, xmm5
; X64-NEXT:    movdqa xmm8, xmm7
; X64-NEXT:    pandn xmm8, xmm4
; X64-NEXT:    psraw xmm4, 0x2
; X64-NEXT:    pand xmm4, xmm7
; X64-NEXT:    por xmm4, xmm8
; X64-NEXT:    paddw xmm5, xmm5
; X64-NEXT:    pxor xmm7, xmm7
; X64-NEXT:    pcmpgtw xmm7, xmm5
; X64-NEXT:    movdqa xmm5, xmm7
; X64-NEXT:    pandn xmm5, xmm4
; X64-NEXT:    psraw xmm4, 0x1
; X64-NEXT:    pand xmm4, xmm7
; X64-NEXT:    por xmm4, xmm5
; X64-NEXT:    psrlw xmm4, 0x8
; X64-NEXT:    punpcklbw {{.*#+}} xmm0 = xmm0[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    punpcklbw {{.*#+}} xmm2 = xmm2[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    pxor xmm5, xmm5
; X64-NEXT:    pcmpgtw xmm5, xmm2
; X64-NEXT:    movdqa xmm7, xmm5
; X64-NEXT:    pandn xmm7, xmm0
; X64-NEXT:    psraw xmm0, 0x4
; X64-NEXT:    pand xmm0, xmm5
; X64-NEXT:    por xmm0, xmm7
; X64-NEXT:    paddw xmm2, xmm2
; X64-NEXT:    pxor xmm5, xmm5
; X64-NEXT:    pcmpgtw xmm5, xmm2
; X64-NEXT:    movdqa xmm7, xmm5
; X64-NEXT:    pandn xmm7, xmm0
; X64-NEXT:    psraw xmm0, 0x2
; X64-NEXT:    pand xmm0, xmm5
; X64-NEXT:    por xmm0, xmm7
; X64-NEXT:    paddw xmm2, xmm2
; X64-NEXT:    pcmpgtw xmm6, xmm2
; X64-NEXT:    movdqa xmm2, xmm6
; X64-NEXT:    pandn xmm2, xmm0
; X64-NEXT:    psraw xmm0, 0x1
; X64-NEXT:    pand xmm0, xmm6
; X64-NEXT:    por xmm0, xmm2
; X64-NEXT:    psrlw xmm0, 0x8
; X64-NEXT:    packuswb xmm0, xmm4
; X64-NEXT:    punpckhbw {{.*#+}} xmm2 = xmm2[8],xmm1[8],xmm2[9],xmm1[9],xmm2[10],xmm1[10],xmm2[11],xmm1[11],xmm2[12],xmm1[12],xmm2[13],xmm1[13],xmm2[14],xmm1[14],xmm2[15],xmm1[15]
; X64-NEXT:    psllw xmm3, 0x5
; X64-NEXT:    punpckhbw {{.*#+}} xmm4 = xmm4[8],xmm3[8],xmm4[9],xmm3[9],xmm4[10],xmm3[10],xmm4[11],xmm3[11],xmm4[12],xmm3[12],xmm4[13],xmm3[13],xmm4[14],xmm3[14],xmm4[15],xmm3[15]
; X64-NEXT:    pxor xmm5, xmm5
; X64-NEXT:    pxor xmm6, xmm6
; X64-NEXT:    pcmpgtw xmm6, xmm4
; X64-NEXT:    movdqa xmm7, xmm6
; X64-NEXT:    pandn xmm7, xmm2
; X64-NEXT:    psraw xmm2, 0x4
; X64-NEXT:    pand xmm2, xmm6
; X64-NEXT:    por xmm2, xmm7
; X64-NEXT:    paddw xmm4, xmm4
; X64-NEXT:    pxor xmm6, xmm6
; X64-NEXT:    pcmpgtw xmm6, xmm4
; X64-NEXT:    movdqa xmm7, xmm6
; X64-NEXT:    pandn xmm7, xmm2
; X64-NEXT:    psraw xmm2, 0x2
; X64-NEXT:    pand xmm2, xmm6
; X64-NEXT:    por xmm2, xmm7
; X64-NEXT:    paddw xmm4, xmm4
; X64-NEXT:    pxor xmm6, xmm6
; X64-NEXT:    pcmpgtw xmm6, xmm4
; X64-NEXT:    movdqa xmm4, xmm6
; X64-NEXT:    pandn xmm4, xmm2
; X64-NEXT:    psraw xmm2, 0x1
; X64-NEXT:    pand xmm2, xmm6
; X64-NEXT:    por xmm2, xmm4
; X64-NEXT:    psrlw xmm2, 0x8
; X64-NEXT:    punpcklbw {{.*#+}} xmm1 = xmm1[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    punpcklbw {{.*#+}} xmm3 = xmm3[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    pxor xmm4, xmm4
; X64-NEXT:    pcmpgtw xmm4, xmm3
; X64-NEXT:    movdqa xmm6, xmm4
; X64-NEXT:    pandn xmm6, xmm1
; X64-NEXT:    psraw xmm1, 0x4
; X64-NEXT:    pand xmm1, xmm4
; X64-NEXT:    por xmm1, xmm6
; X64-NEXT:    paddw xmm3, xmm3
; X64-NEXT:    pxor xmm4, xmm4
; X64-NEXT:    pcmpgtw xmm4, xmm3
; X64-NEXT:    movdqa xmm6, xmm4
; X64-NEXT:    pandn xmm6, xmm1
; X64-NEXT:    psraw xmm1, 0x2
; X64-NEXT:    pand xmm1, xmm4
; X64-NEXT:    por xmm1, xmm6
; X64-NEXT:    paddw xmm3, xmm3
; X64-NEXT:    pcmpgtw xmm5, xmm3
; X64-NEXT:    movdqa xmm3, xmm5
; X64-NEXT:    pandn xmm3, xmm1
; X64-NEXT:    psraw xmm1, 0x1
; X64-NEXT:    pand xmm1, xmm5
; X64-NEXT:    por xmm1, xmm3
; X64-NEXT:    psrlw xmm1, 0x8
; X64-NEXT:    packuswb xmm1, xmm2
; X64-NEXT:    movups xmmword ptr [rdi], xmm0
; X64-NEXT:    movups xmmword ptr [rdi + 0x10], xmm1
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v32i8>:
; ARM64:         ldr q0, [x0]
; ARM64-NEXT:    ldr q1, [x0, #0x10]
; ARM64-NEXT:    ldr q2, [x1]
; ARM64-NEXT:    ldr q3, [x1, #0x10]
; ARM64-NEXT:    neg v2.16b, v2.16b
; ARM64-NEXT:    sshl v0.16b, v0.16b, v2.16b
; ARM64-NEXT:    neg v3.16b, v3.16b
; ARM64-NEXT:    sshl v1.16b, v1.16b, v3.16b
; ARM64-NEXT:    str q0, [x0]
; ARM64-NEXT:    str q1, [x0, #0x10]
; ARM64-NEXT:    ret
  %a = load <32 x i8>, ptr %p
  %b = load <32 x i8>, ptr %q
  %r = ashr <32 x i8> %a, %b
  store <32 x i8> %r, ptr %p
  ret void
}

define void @ashr_v32i8_3(ptr %p) {
; X64-LABEL: <ashr_v32i8_3>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movups xmm0, xmmword ptr [rdi]
; X64-NEXT:    movups xmm1, xmmword ptr [rdi + 0x10]
; X64-NEXT:    punpckhbw {{.*#+}} xmm2 = xmm2[8],xmm0[8],xmm2[9],xmm0[9],xmm2[10],xmm0[10],xmm2[11],xmm0[11],xmm2[12],xmm0[12],xmm2[13],xmm0[13],xmm2[14],xmm0[14],xmm2[15],xmm0[15]
; X64-NEXT:    movaps xmm3, xmmword ptr <ashr_v32i8_3+0xe>
; X64-NEXT:     R_X86_64_PC32 -0x4
; X64-NEXT:    psllw xmm3, 0x5
; X64-NEXT:    punpckhbw {{.*#+}} xmm4 = xmm4[8],xmm3[8],xmm4[9],xmm3[9],xmm4[10],xmm3[10],xmm4[11],xmm3[11],xmm4[12],xmm3[12],xmm4[13],xmm3[13],xmm4[14],xmm3[14],xmm4[15],xmm3[15]
; X64-NEXT:    pxor xmm5, xmm5
; X64-NEXT:    pxor xmm6, xmm6
; X64-NEXT:    pcmpgtw xmm6, xmm4
; X64-NEXT:    movdqa xmm7, xmm6
; X64-NEXT:    pandn xmm7, xmm2
; X64-NEXT:    psraw xmm2, 0x4
; X64-NEXT:    pand xmm2, xmm6
; X64-NEXT:    por xmm2, xmm7
; X64-NEXT:    paddw xmm4, xmm4
; X64-NEXT:    pxor xmm6, xmm6
; X64-NEXT:    pcmpgtw xmm6, xmm4
; X64-NEXT:    movdqa xmm7, xmm6
; X64-NEXT:    pandn xmm7, xmm2
; X64-NEXT:    psraw xmm2, 0x2
; X64-NEXT:    pand xmm2, xmm6
; X64-NEXT:    por xmm2, xmm7
; X64-NEXT:    paddw xmm4, xmm4
; X64-NEXT:    pxor xmm6, xmm6
; X64-NEXT:    pcmpgtw xmm6, xmm4
; X64-NEXT:    movdqa xmm4, xmm6
; X64-NEXT:    pandn xmm4, xmm2
; X64-NEXT:    psraw xmm2, 0x1
; X64-NEXT:    pand xmm2, xmm6
; X64-NEXT:    por xmm2, xmm4
; X64-NEXT:    psrlw xmm2, 0x8
; X64-NEXT:    punpcklbw {{.*#+}} xmm0 = xmm0[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    punpcklbw {{.*#+}} xmm3 = xmm3[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    pxor xmm4, xmm4
; X64-NEXT:    pcmpgtw xmm4, xmm3
; X64-NEXT:    movdqa xmm6, xmm4
; X64-NEXT:    pandn xmm6, xmm0
; X64-NEXT:    psraw xmm0, 0x4
; X64-NEXT:    pand xmm0, xmm4
; X64-NEXT:    por xmm0, xmm6
; X64-NEXT:    paddw xmm3, xmm3
; X64-NEXT:    pxor xmm4, xmm4
; X64-NEXT:    pcmpgtw xmm4, xmm3
; X64-NEXT:    movdqa xmm6, xmm4
; X64-NEXT:    pandn xmm6, xmm0
; X64-NEXT:    psraw xmm0, 0x2
; X64-NEXT:    pand xmm0, xmm4
; X64-NEXT:    por xmm0, xmm6
; X64-NEXT:    paddw xmm3, xmm3
; X64-NEXT:    pcmpgtw xmm5, xmm3
; X64-NEXT:    movdqa xmm3, xmm5
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x1
; X64-NEXT:    pand xmm0, xmm5
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    psrlw xmm0, 0x8
; X64-NEXT:    packuswb xmm0, xmm2
; X64-NEXT:    punpckhbw {{.*#+}} xmm2 = xmm2[8],xmm1[8],xmm2[9],xmm1[9],xmm2[10],xmm1[10],xmm2[11],xmm1[11],xmm2[12],xmm1[12],xmm2[13],xmm1[13],xmm2[14],xmm1[14],xmm2[15],xmm1[15]
; X64-NEXT:    movaps xmm3, xmmword ptr <ashr_v32i8_3+0xf6>
; X64-NEXT:     R_X86_64_PC32 -0x4
; X64-NEXT:    psllw xmm3, 0x5
; X64-NEXT:    punpckhbw {{.*#+}} xmm4 = xmm4[8],xmm3[8],xmm4[9],xmm3[9],xmm4[10],xmm3[10],xmm4[11],xmm3[11],xmm4[12],xmm3[12],xmm4[13],xmm3[13],xmm4[14],xmm3[14],xmm4[15],xmm3[15]
; X64-NEXT:    pxor xmm5, xmm5
; X64-NEXT:    pxor xmm6, xmm6
; X64-NEXT:    pcmpgtw xmm6, xmm4
; X64-NEXT:    movdqa xmm7, xmm6
; X64-NEXT:    pandn xmm7, xmm2
; X64-NEXT:    psraw xmm2, 0x4
; X64-NEXT:    pand xmm2, xmm6
; X64-NEXT:    por xmm2, xmm7
; X64-NEXT:    paddw xmm4, xmm4
; X64-NEXT:    pxor xmm6, xmm6
; X64-NEXT:    pcmpgtw xmm6, xmm4
; X64-NEXT:    movdqa xmm7, xmm6
; X64-NEXT:    pandn xmm7, xmm2
; X64-NEXT:    psraw xmm2, 0x2
; X64-NEXT:    pand xmm2, xmm6
; X64-NEXT:    por xmm2, xmm7
; X64-NEXT:    paddw xmm4, xmm4
; X64-NEXT:    pxor xmm6, xmm6
; X64-NEXT:    pcmpgtw xmm6, xmm4
; X64-NEXT:    movdqa xmm4, xmm6
; X64-NEXT:    pandn xmm4, xmm2
; X64-NEXT:    psraw xmm2, 0x1
; X64-NEXT:    pand xmm2, xmm6
; X64-NEXT:    por xmm2, xmm4
; X64-NEXT:    psrlw xmm2, 0x8
; X64-NEXT:    punpcklbw {{.*#+}} xmm1 = xmm1[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    punpcklbw {{.*#+}} xmm3 = xmm3[0,0,1,1,2,2,3,3,4,4,5,5,6,6,7,7]
; X64-NEXT:    pxor xmm4, xmm4
; X64-NEXT:    pcmpgtw xmm4, xmm3
; X64-NEXT:    movdqa xmm6, xmm4
; X64-NEXT:    pandn xmm6, xmm1
; X64-NEXT:    psraw xmm1, 0x4
; X64-NEXT:    pand xmm1, xmm4
; X64-NEXT:    por xmm1, xmm6
; X64-NEXT:    paddw xmm3, xmm3
; X64-NEXT:    pxor xmm4, xmm4
; X64-NEXT:    pcmpgtw xmm4, xmm3
; X64-NEXT:    movdqa xmm6, xmm4
; X64-NEXT:    pandn xmm6, xmm1
; X64-NEXT:    psraw xmm1, 0x2
; X64-NEXT:    pand xmm1, xmm4
; X64-NEXT:    por xmm1, xmm6
; X64-NEXT:    paddw xmm3, xmm3
; X64-NEXT:    pcmpgtw xmm5, xmm3
; X64-NEXT:    movdqa xmm3, xmm5
; X64-NEXT:    pandn xmm3, xmm1
; X64-NEXT:    psraw xmm1, 0x1
; X64-NEXT:    pand xmm1, xmm5
; X64-NEXT:    por xmm1, xmm3
; X64-NEXT:    psrlw xmm1, 0x8
; X64-NEXT:    packuswb xmm1, xmm2
; X64-NEXT:    movups xmmword ptr [rdi], xmm0
; X64-NEXT:    movups xmmword ptr [rdi + 0x10], xmm1
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v32i8_3>:
; ARM64:         ldr q0, [x0]
; ARM64-NEXT:    ldr q1, [x0, #0x10]
; ARM64-NEXT:    movi v2.16b, #0x3
; ARM64-NEXT:    neg v2.16b, v2.16b
; ARM64-NEXT:    sshl v0.16b, v0.16b, v2.16b
; ARM64-NEXT:    movi v2.16b, #0x3
; ARM64-NEXT:    neg v2.16b, v2.16b
; ARM64-NEXT:    sshl v1.16b, v1.16b, v2.16b
; ARM64-NEXT:    str q0, [x0]
; ARM64-NEXT:    str q1, [x0, #0x10]
; ARM64-NEXT:    ret
  %a = load <32 x i8>, ptr %p
  %r = ashr <32 x i8> %a, <i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3, i8 3>
  store <32 x i8> %r, ptr %p
  ret void
}

define <4 x i16> @ashr_v4i16(<4 x i16> %a, <4 x i16> %b) {
; X64-LABEL: <ashr_v4i16>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    psllw xmm1, 0xc
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    psraw xmm2, 0xf
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x8
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    psraw xmm2, 0xf
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x4
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    psraw xmm2, 0xf
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x2
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    psraw xmm1, 0xf
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    pandn xmm2, xmm0
; X64-NEXT:    psraw xmm0, 0x1
; X64-NEXT:    pand xmm0, xmm1
; X64-NEXT:    por xmm0, xmm2
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v4i16>:
; ARM64:         neg v1.4h, v1.4h
; ARM64-NEXT:    sshl v0.4h, v0.4h, v1.4h
; ARM64-NEXT:    ret
  %r = ashr <4 x i16> %a, %b
  ret <4 x i16> %r
}

define <4 x i16> @ashr_v4i16_3(<4 x i16> %a) {
; X64-LABEL: <ashr_v4i16_3>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movabs rax, 0x3000300030003
; X64-NEXT:    movq xmm1, rax
; X64-NEXT:    psllw xmm1, 0xc
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    psraw xmm2, 0xf
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x8
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    psraw xmm2, 0xf
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x4
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    psraw xmm2, 0xf
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x2
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    psraw xmm1, 0xf
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    pandn xmm2, xmm0
; X64-NEXT:    psraw xmm0, 0x1
; X64-NEXT:    pand xmm0, xmm1
; X64-NEXT:    por xmm0, xmm2
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v4i16_3>:
; ARM64:         movi v1.4h, #0x3
; ARM64-NEXT:    neg v1.4h, v1.4h
; ARM64-NEXT:    sshl v0.4h, v0.4h, v1.4h
; ARM64-NEXT:    ret
  %r = ashr <4 x i16> %a, <i16 3, i16 3, i16 3, i16 3>
  ret <4 x i16> %r
}

define <8 x i16> @ashr_v8i16(<8 x i16> %a, <8 x i16> %b) {
; X64-LABEL: <ashr_v8i16>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    psllw xmm1, 0xc
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    psraw xmm2, 0xf
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x8
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    psraw xmm2, 0xf
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x4
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    psraw xmm2, 0xf
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x2
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    psraw xmm1, 0xf
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    pandn xmm2, xmm0
; X64-NEXT:    psraw xmm0, 0x1
; X64-NEXT:    pand xmm0, xmm1
; X64-NEXT:    por xmm0, xmm2
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v8i16>:
; ARM64:         neg v1.8h, v1.8h
; ARM64-NEXT:    sshl v0.8h, v0.8h, v1.8h
; ARM64-NEXT:    ret
  %r = ashr <8 x i16> %a, %b
  ret <8 x i16> %r
}

define <8 x i16> @ashr_v8i16_3(<8 x i16> %a) {
; X64-LABEL: <ashr_v8i16_3>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movaps xmm1, xmmword ptr <ashr_v8i16_3+0x3>
; X64-NEXT:     R_X86_64_PC32 -0x4
; X64-NEXT:    psllw xmm1, 0xc
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    psraw xmm2, 0xf
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x8
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    psraw xmm2, 0xf
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x4
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    psraw xmm2, 0xf
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    pandn xmm3, xmm0
; X64-NEXT:    psraw xmm0, 0x2
; X64-NEXT:    pand xmm0, xmm2
; X64-NEXT:    por xmm0, xmm3
; X64-NEXT:    paddw xmm1, xmm1
; X64-NEXT:    psraw xmm1, 0xf
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    pandn xmm2, xmm0
; X64-NEXT:    psraw xmm0, 0x1
; X64-NEXT:    pand xmm0, xmm1
; X64-NEXT:    por xmm0, xmm2
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v8i16_3>:
; ARM64:         movi v1.8h, #0x3
; ARM64-NEXT:    neg v1.8h, v1.8h
; ARM64-NEXT:    sshl v0.8h, v0.8h, v1.8h
; ARM64-NEXT:    ret
  %r = ashr <8 x i16> %a, <i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3, i16 3>
  ret <8 x i16> %r
}

define <2 x i32> @ashr_v2i32(<2 x i32> %a, <2 x i32> %b) {
; X64-LABEL: <ashr_v2i32>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    pshuflw {{.*#+}} xmm2 = xmm1[2,3,3,3,4,5,6,7]
; X64-NEXT:    movapd xmm3, xmm0
; X64-NEXT:    shufps {{.*#+}} xmm3 = xmm3[1,1],xmm0[1,1]
; X64-NEXT:    psrad xmm3, xmm2
; X64-NEXT:    pshuflw {{.*#+}} xmm1 = xmm1[0,1,1,1,4,5,6,7]
; X64-NEXT:    psrad xmm0, xmm1
; X64-NEXT:    punpckldq {{.*#+}} xmm0 = xmm0[0],xmm3[0],xmm0[1],xmm3[1]
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v2i32>:
; ARM64:         neg v1.2s, v1.2s
; ARM64-NEXT:    sshl v0.2s, v0.2s, v1.2s
; ARM64-NEXT:    ret
  %r = ashr <2 x i32> %a, %b
  ret <2 x i32> %r
}

define <2 x i32> @ashr_v2i32_3(<2 x i32> %a) {
; X64-LABEL: <ashr_v2i32_3>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movabs rax, 0x300000003
; X64-NEXT:    movq xmm1, rax
; X64-NEXT:    pshuflw {{.*#+}} xmm2 = xmm1[2,3,3,3,4,5,6,7]
; X64-NEXT:    movapd xmm3, xmm0
; X64-NEXT:    shufps {{.*#+}} xmm3 = xmm3[1,1],xmm0[1,1]
; X64-NEXT:    psrad xmm3, xmm2
; X64-NEXT:    pshuflw {{.*#+}} xmm1 = xmm1[0,1,1,1,4,5,6,7]
; X64-NEXT:    psrad xmm0, xmm1
; X64-NEXT:    punpckldq {{.*#+}} xmm0 = xmm0[0],xmm3[0],xmm0[1],xmm3[1]
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v2i32_3>:
; ARM64:         movi v1.2s, #0x3
; ARM64-NEXT:    neg v1.2s, v1.2s
; ARM64-NEXT:    sshl v0.2s, v0.2s, v1.2s
; ARM64-NEXT:    ret
  %r = ashr <2 x i32> %a, <i32 3, i32 3>
  ret <2 x i32> %r
}

define <4 x i32> @ashr_v4i32(<4 x i32> %a, <4 x i32> %b) {
; X64-LABEL: <ashr_v4i32>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    pshuflw {{.*#+}} xmm2 = xmm1[2,3,3,3,4,5,6,7]
; X64-NEXT:    movapd xmm3, xmm0
; X64-NEXT:    psrad xmm3, xmm2
; X64-NEXT:    pshuflw {{.*#+}} xmm4 = xmm1[0,1,1,1,4,5,6,7]
; X64-NEXT:    movapd xmm2, xmm0
; X64-NEXT:    psrad xmm2, xmm4
; X64-NEXT:    punpcklqdq {{.*#+}} xmm2 = xmm2[0],xmm3[0]
; X64-NEXT:    pshufd {{.*#+}} xmm1 = xmm1[2,3,2,3]
; X64-NEXT:    pshuflw {{.*#+}} xmm3 = xmm1[2,3,3,3,4,5,6,7]
; X64-NEXT:    movapd xmm4, xmm0
; X64-NEXT:    psrad xmm4, xmm3
; X64-NEXT:    pshuflw {{.*#+}} xmm1 = xmm1[0,1,1,1,4,5,6,7]
; X64-NEXT:    psrad xmm0, xmm1
; X64-NEXT:    punpckhqdq {{.*#+}} xmm0 = xmm0[1],xmm4[1]
; X64-NEXT:    shufps {{.*#+}} xmm2 = xmm2[0,3],xmm0[0,3]
; X64-NEXT:    movapd xmm0, xmm2
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v4i32>:
; ARM64:         neg v1.4s, v1.4s
; ARM64-NEXT:    sshl v0.4s, v0.4s, v1.4s
; ARM64-NEXT:    ret
  %r = ashr <4 x i32> %a, %b
  ret <4 x i32> %r
}

define <4 x i32> @ashr_v4i32_3(<4 x i32> %a) {
; X64-LABEL: <ashr_v4i32_3>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movaps xmm1, xmmword ptr <ashr_v4i32_3+0x3>
; X64-NEXT:     R_X86_64_PC32 -0x4
; X64-NEXT:    pshuflw {{.*#+}} xmm2 = xmm1[2,3,3,3,4,5,6,7]
; X64-NEXT:    movapd xmm3, xmm0
; X64-NEXT:    psrad xmm3, xmm2
; X64-NEXT:    pshuflw {{.*#+}} xmm4 = xmm1[0,1,1,1,4,5,6,7]
; X64-NEXT:    movapd xmm2, xmm0
; X64-NEXT:    psrad xmm2, xmm4
; X64-NEXT:    punpcklqdq {{.*#+}} xmm2 = xmm2[0],xmm3[0]
; X64-NEXT:    pshufd {{.*#+}} xmm1 = xmm1[2,3,2,3]
; X64-NEXT:    pshuflw {{.*#+}} xmm3 = xmm1[2,3,3,3,4,5,6,7]
; X64-NEXT:    movapd xmm4, xmm0
; X64-NEXT:    psrad xmm4, xmm3
; X64-NEXT:    pshuflw {{.*#+}} xmm1 = xmm1[0,1,1,1,4,5,6,7]
; X64-NEXT:    psrad xmm0, xmm1
; X64-NEXT:    punpckhqdq {{.*#+}} xmm0 = xmm0[1],xmm4[1]
; X64-NEXT:    shufps {{.*#+}} xmm2 = xmm2[0,3],xmm0[0,3]
; X64-NEXT:    movapd xmm0, xmm2
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v4i32_3>:
; ARM64:         movi v1.4s, #0x3
; ARM64-NEXT:    neg v1.4s, v1.4s
; ARM64-NEXT:    sshl v0.4s, v0.4s, v1.4s
; ARM64-NEXT:    ret
  %r = ashr <4 x i32> %a, <i32 3, i32 3, i32 3, i32 3>
  ret <4 x i32> %r
}

define <2 x i64> @ashr_v2i64(<2 x i64> %a, <2 x i64> %b) {
; X64-LABEL: <ashr_v2i64>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movdqa xmm2, xmmword ptr <ashr_v2i64+0x4>
; X64-NEXT:     R_X86_64_PC32 -0x4
; X64-NEXT:    movdqa xmm3, xmm2
; X64-NEXT:    psrlq xmm3, xmm1
; X64-NEXT:    pshufd {{.*#+}} xmm4 = xmm1[2,3,2,3]
; X64-NEXT:    psrlq xmm2, xmm4
; X64-NEXT:    movsd {{.*#+}} xmm2 = xmm3[0],xmm2[1]
; X64-NEXT:    movapd xmm3, xmm0
; X64-NEXT:    psrlq xmm3, xmm1
; X64-NEXT:    psrlq xmm0, xmm4
; X64-NEXT:    movsd {{.*#+}} xmm0 = xmm3[0],xmm0[1]
; X64-NEXT:    xorpd xmm0, xmm2
; X64-NEXT:    psubq xmm0, xmm2
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v2i64>:
; ARM64:         neg v1.2d, v1.2d
; ARM64-NEXT:    sshl v0.2d, v0.2d, v1.2d
; ARM64-NEXT:    ret
  %r = ashr <2 x i64> %a, %b
  ret <2 x i64> %r
}

define <2 x i64> @ashr_v2i64_3(<2 x i64> %a) {
; X64-LABEL: <ashr_v2i64_3>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movdqa xmm1, xmmword ptr <ashr_v2i64_3+0x4>
; X64-NEXT:     R_X86_64_PC32 -0x4
; X64-NEXT:    movdqa xmm2, xmm1
; X64-NEXT:    movaps xmm3, xmmword ptr <ashr_v2i64_3+0xf>
; X64-NEXT:     R_X86_64_PC32 -0x4
; X64-NEXT:    psrlq xmm2, xmm3
; X64-NEXT:    pshufd {{.*#+}} xmm4 = xmm3[2,3,2,3]
; X64-NEXT:    psrlq xmm1, xmm4
; X64-NEXT:    movsd {{.*#+}} xmm1 = xmm2[0],xmm1[1]
; X64-NEXT:    movapd xmm2, xmm0
; X64-NEXT:    psrlq xmm2, xmm3
; X64-NEXT:    psrlq xmm0, xmm4
; X64-NEXT:    movsd {{.*#+}} xmm0 = xmm2[0],xmm0[1]
; X64-NEXT:    xorpd xmm0, xmm1
; X64-NEXT:    psubq xmm0, xmm1
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <ashr_v2i64_3>:
; ARM64:         adrp x16, 0x0 <ashr_v1i8>
; ARM64-NEXT:     R_AARCH64_ADR_PREL_PG_HI21
; ARM64-NEXT:    ldr q1, [x16]
; ARM64-NEXT:     R_AARCH64_LDST128_ABS_LO12_NC
; ARM64-NEXT:    neg v1.2d, v1.2d
; ARM64-NEXT:    sshl v0.2d, v0.2d, v1.2d
; ARM64-NEXT:    ret
  %r = ashr <2 x i64> %a, <i64 3, i64 3>
  ret <2 x i64> %r
}
