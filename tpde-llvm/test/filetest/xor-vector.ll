; NOTE: Assertions have been autogenerated by test/update_tpde_llc_test_checks.py UTC_ARGS: --version 5
; SPDX-FileCopyrightText: 2025 Contributors to TPDE <https://tpde.org>
; SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

; RUN: tpde-llc --target=x86_64 %s | %objdump | FileCheck %s -check-prefixes=X64
; RUN: tpde-llc --target=aarch64 %s | %objdump | FileCheck %s -check-prefixes=ARM64

define <8 x i8> @xor_v8i8(<8 x i8> %a, <8 x i8> %b) {
; X64-LABEL: <xor_v8i8>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    xorps xmm0, xmm1
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v8i8>:
; ARM64:         eor v1.8b, v1.8b, v0.8b
; ARM64-NEXT:    mov v0.16b, v1.16b
; ARM64-NEXT:    ret
  %r = xor <8 x i8> %a, %b
  ret <8 x i8> %r
}

define <16 x i8> @xor_v16i8(<16 x i8> %a, <16 x i8> %b) {
; X64-LABEL: <xor_v16i8>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    xorps xmm0, xmm1
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v16i8>:
; ARM64:         eor v1.16b, v1.16b, v0.16b
; ARM64-NEXT:    mov v0.16b, v1.16b
; ARM64-NEXT:    ret
  %r = xor <16 x i8> %a, %b
  ret <16 x i8> %r
}

define <4 x i16> @xor_v4i16(<4 x i16> %a, <4 x i16> %b) {
; X64-LABEL: <xor_v4i16>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    xorps xmm0, xmm1
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v4i16>:
; ARM64:         eor v1.8b, v1.8b, v0.8b
; ARM64-NEXT:    mov v0.16b, v1.16b
; ARM64-NEXT:    ret
  %r = xor <4 x i16> %a, %b
  ret <4 x i16> %r
}

define <8 x i16> @xor_v8i16(<8 x i16> %a, <8 x i16> %b) {
; X64-LABEL: <xor_v8i16>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    xorps xmm0, xmm1
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v8i16>:
; ARM64:         eor v1.16b, v1.16b, v0.16b
; ARM64-NEXT:    mov v0.16b, v1.16b
; ARM64-NEXT:    ret
  %r = xor <8 x i16> %a, %b
  ret <8 x i16> %r
}

define <2 x i32> @xor_v2i32(<2 x i32> %a, <2 x i32> %b) {
; X64-LABEL: <xor_v2i32>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    xorps xmm0, xmm1
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v2i32>:
; ARM64:         eor v1.8b, v1.8b, v0.8b
; ARM64-NEXT:    mov v0.16b, v1.16b
; ARM64-NEXT:    ret
  %r = xor <2 x i32> %a, %b
  ret <2 x i32> %r
}

define <4 x i32> @xor_v4i32(<4 x i32> %a, <4 x i32> %b) {
; X64-LABEL: <xor_v4i32>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    xorps xmm0, xmm1
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v4i32>:
; ARM64:         eor v1.16b, v1.16b, v0.16b
; ARM64-NEXT:    mov v0.16b, v1.16b
; ARM64-NEXT:    ret
  %r = xor <4 x i32> %a, %b
  ret <4 x i32> %r
}

define <2 x i64> @xor_v2i64(<2 x i64> %a, <2 x i64> %b) {
; X64-LABEL: <xor_v2i64>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    xorps xmm0, xmm1
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v2i64>:
; ARM64:         eor v1.16b, v1.16b, v0.16b
; ARM64-NEXT:    mov v0.16b, v1.16b
; ARM64-NEXT:    ret
  %r = xor <2 x i64> %a, %b
  ret <2 x i64> %r
}

define void @xor_v4i1(ptr %p, ptr %q) {
; X64-LABEL: <xor_v4i1>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movzx eax, byte ptr [rdi]
; X64-NEXT:    movzx esi, byte ptr [rsi]
; X64-NEXT:    xor eax, esi
; X64-NEXT:    mov byte ptr [rdi], al
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v4i1>:
; ARM64:         ldrb w2, [x0]
; ARM64-NEXT:    ldrb w1, [x1]
; ARM64-NEXT:    eor w1, w1, w2
; ARM64-NEXT:    strb w1, [x0]
; ARM64-NEXT:    ret
  %a = load <4 x i1>, ptr %p
  %b = load <4 x i1>, ptr %q
  %r = xor <4 x i1> %a, %b
  store <4 x i1> %r, ptr %p
  ret void
}

define void @xor_v4i1_const(ptr %p) {
; X64-LABEL: <xor_v4i1_const>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movzx eax, byte ptr [rdi]
; X64-NEXT:    xor eax, 0x5
; X64-NEXT:    mov byte ptr [rdi], al
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v4i1_const>:
; ARM64:         ldrb w1, [x0]
; ARM64-NEXT:    mov x2, #0x5 // =5
; ARM64-NEXT:    eor w2, w2, w1
; ARM64-NEXT:    strb w2, [x0]
; ARM64-NEXT:    ret
  %a = load <4 x i1>, ptr %p
  %r = xor <4 x i1> %a, <i1 1, i1 0, i1 1, i1 0>
  store <4 x i1> %r, ptr %p
  ret void
}

define void @xor_v8i1(ptr %p, ptr %q) {
; X64-LABEL: <xor_v8i1>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movzx eax, byte ptr [rdi]
; X64-NEXT:    movzx esi, byte ptr [rsi]
; X64-NEXT:    xor eax, esi
; X64-NEXT:    mov byte ptr [rdi], al
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v8i1>:
; ARM64:         ldrb w2, [x0]
; ARM64-NEXT:    ldrb w1, [x1]
; ARM64-NEXT:    eor w1, w1, w2
; ARM64-NEXT:    strb w1, [x0]
; ARM64-NEXT:    ret
  %a = load <8 x i1>, ptr %p
  %b = load <8 x i1>, ptr %q
  %r = xor <8 x i1> %a, %b
  store <8 x i1> %r, ptr %p
  ret void
}

define void @xor_v8i1_const(ptr %p) {
; X64-LABEL: <xor_v8i1_const>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    movzx eax, byte ptr [rdi]
; X64-NEXT:    xor eax, 0x55
; X64-NEXT:    mov byte ptr [rdi], al
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v8i1_const>:
; ARM64:         ldrb w1, [x0]
; ARM64-NEXT:    mov x2, #0x55 // =85
; ARM64-NEXT:    eor w2, w2, w1
; ARM64-NEXT:    strb w2, [x0]
; ARM64-NEXT:    ret
  %a = load <8 x i1>, ptr %p
  %r = xor <8 x i1> %a, <i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0>
  store <8 x i1> %r, ptr %p
  ret void
}

define void @xor_v32i1(ptr %p, ptr %q) {
; X64-LABEL: <xor_v32i1>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    mov eax, dword ptr [rdi]
; X64-NEXT:    mov esi, dword ptr [rsi]
; X64-NEXT:    xor eax, esi
; X64-NEXT:    mov dword ptr [rdi], eax
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v32i1>:
; ARM64:         ldr w2, [x0]
; ARM64-NEXT:    ldr w1, [x1]
; ARM64-NEXT:    eor w1, w1, w2
; ARM64-NEXT:    str w1, [x0]
; ARM64-NEXT:    ret
  %a = load <32 x i1>, ptr %p
  %b = load <32 x i1>, ptr %q
  %r = xor <32 x i1> %a, %b
  store <32 x i1> %r, ptr %p
  ret void
}

define void @xor_v32i1_const(ptr %p) {
; X64-LABEL: <xor_v32i1_const>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    mov eax, dword ptr [rdi]
; X64-NEXT:    xor eax, 0x55555555
; X64-NEXT:    mov dword ptr [rdi], eax
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v32i1_const>:
; ARM64:         ldr w1, [x0]
; ARM64-NEXT:    eor w1, w1, #0x55555555
; ARM64-NEXT:    str w1, [x0]
; ARM64-NEXT:    ret
  %a = load <32 x i1>, ptr %p
  %r = xor <32 x i1> %a, <i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0>
  store <32 x i1> %r, ptr %p
  ret void
}

define void @xor_v64i1(ptr %p, ptr %q) {
; X64-LABEL: <xor_v64i1>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    mov rax, qword ptr [rdi]
; X64-NEXT:    mov rsi, qword ptr [rsi]
; X64-NEXT:    xor rax, rsi
; X64-NEXT:    mov qword ptr [rdi], rax
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v64i1>:
; ARM64:         ldr x2, [x0]
; ARM64-NEXT:    ldr x1, [x1]
; ARM64-NEXT:    eor x1, x1, x2
; ARM64-NEXT:    str x1, [x0]
; ARM64-NEXT:    ret
  %a = load <64 x i1>, ptr %p
  %b = load <64 x i1>, ptr %q
  %r = xor <64 x i1> %a, %b
  store <64 x i1> %r, ptr %p
  ret void
}
define void @xor_v64i1_const(ptr %p) {
; X64-LABEL: <xor_v64i1_const>:
; X64:         push rbp
; X64-NEXT:    mov rbp, rsp
; X64-NEXT:    mov rax, qword ptr [rdi]
; X64-NEXT:    movabs rcx, 0x5555555555555555
; X64-NEXT:    xor rax, rcx
; X64-NEXT:    mov qword ptr [rdi], rax
; X64-NEXT:    pop rbp
; X64-NEXT:    ret
;
; ARM64-LABEL: <xor_v64i1_const>:
; ARM64:         ldr x1, [x0]
; ARM64-NEXT:    eor x1, x1, #0x5555555555555555
; ARM64-NEXT:    str x1, [x0]
; ARM64-NEXT:    ret
  %a = load <64 x i1>, ptr %p
  %r = xor <64 x i1> %a, <i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0, i1 1, i1 0>
  store <64 x i1> %r, ptr %p
  ret void
}
